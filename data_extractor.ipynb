{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing JSON: unterminated string literal (detected at line 3) (<string>, line 3)\n",
      "     video_id                                          questions\n",
      "0   698894249  {'question1': 'How would you ensure that the w...\n",
      "1   698893976  {'question1': 'What are the different ways in ...\n",
      "2   698893499  {'question1': 'How is Vijay related to Hari?',...\n",
      "3   698488529  {'question1': 'What are the steps to create a ...\n",
      "4   698488493  {'question1': 'What are the steps involved in ...\n",
      "..        ...                                                ...\n",
      "61  698477373  {'question1': 'What are the benefits of using ...\n",
      "62  698477243  {'question1': 'What is the replay capability a...\n",
      "63  698477192  {'question1': 'What are the benefits of using ...\n",
      "64  698477136  {'question1': 'What are the benefits of using ...\n",
      "65  698477046  {'question1': 'What is the difference between ...\n",
      "\n",
      "[66 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file_path = \"/media/amhawk/1180b248-3121-46a2-892f-e237b8070717/Projects/logs/12_04_2023/07_12_06.log\"\n",
    "with open(file_path, \"r\") as f:\n",
    "    log_data = f.read()\n",
    "\n",
    "# Extract JSON structures using regex\n",
    "json_pattern = re.compile(r'\\{[^}]*\\}', re.MULTILINE | re.DOTALL)\n",
    "json_matches = re.finditer(json_pattern, log_data)\n",
    "\n",
    "# Extract video IDs using regex\n",
    "video_id_pattern = re.compile(r'video_id : (\\d+)')\n",
    "video_id_matches = re.finditer(video_id_pattern, log_data)\n",
    "\n",
    "# Collect video IDs\n",
    "video_ids = [match.group(1) for match in video_id_matches]\n",
    "\n",
    "# Process JSON structures\n",
    "json_quest = []\n",
    "for match in json_matches:\n",
    "    extracted_json = match.group()\n",
    "    try:\n",
    "        # Use eval cautiously, consider using json.loads for safer JSON parsing\n",
    "        eval_json = eval(extracted_json)\n",
    "        json_quest.append(eval_json)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "\n",
    "# Combine video IDs and JSON structures into a list of dictionaries\n",
    "result_list = [{'video_id': vid, 'questions': json} for vid, json in zip(video_ids, json_quest)]\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(result_list)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./csv_output/ques_2100_2235.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ai21\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "ai21.api_key = os.environ.get(\"AI21_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What are the steps to create a new workflow in Alteryx to split the name column into two different columns?\"\n",
    "question_gen = ai21.Completion.execute(\n",
    "        model='j2-ultra',\n",
    "        prompt=prompt,\n",
    "        numResults=1,\n",
    "        maxTokens=1000,\n",
    "        temperature=0.3,\n",
    "        topKReturn=0,\n",
    "        top_p=1,\n",
    "        stopSequence=['##']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To create a new workflow in Alteryx to split the name column into two different columns, you can follow these steps:\n",
      "\n",
      "1. Open Alteryx Designer and create a new workflow.\n",
      "2. Drag and drop a \"Data Input\" tool onto the canvas.\n",
      "3. Connect the \"Data Input\" tool to a \"Data Output\" tool.\n",
      "4. In the \"Data Input\" tool, select the file or data source that contains the name column you want to split.\n",
      "5. Drag and drop a \"Split Column\" tool onto the canvas.\n",
      "6. Connect the output of the \"Data Input\" tool to the \"Input\" port of the \"Split Column\" tool.\n",
      "7. Connect the \"Output\" port of the \"Split Column\" tool to a \"Data Output\" tool.\n",
      "8. In the \"Split Column\" tool, select the \"Name\" column as the column to split.\n",
      "9. In the \"Split Column\" tool, specify the separator or delimiter that you want to use to split the name column. For example, if you want to split the name column at the space character, you can use a space as the separator.\n",
      "10. In the \"Split Column\" tool, specify the desired output columns for the split names. For example, you can specify one output column for first names and another output column for last names.\n",
      "11. Connect the \"Data Output\" tool to a \"Data Input\" tool to continue the workflow or save the workflow and run it as needed.\n",
      "\n",
      "By following these steps, you should be able to create a new workflow in Alteryx to split the name column into two different columns.\n"
     ]
    }
   ],
   "source": [
    "generated_text = question_gen['completions'][0]['data']['text']\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./ques_1700_1995_mods.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'question1': 'What are the differences betwee...\n",
       "1    {'question1': 'What is the difference between ...\n",
       "2    {'question1': 'What are the different meta cha...\n",
       "3    {'question1': 'What specific aspects of time s...\n",
       "4    {'question1': 'What are the different steps in...\n",
       "Name: questions, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to output.csv.\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Convert the data into a DataFrame\n",
    "df = pd.DataFrame(x)\n",
    "\n",
    "# Convert the 'questions' column from a string to a dictionary\n",
    "df['questions'] = df['questions'].apply(ast.literal_eval)\n",
    "\n",
    "# Expand the dictionary in the 'questions' column into separate columns\n",
    "df = pd.concat([df.drop(['questions'], axis=1), df['questions'].apply(pd.Series)], axis=1)\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "df.to_csv('output.csv', index=False)\n",
    "\n",
    "print('Data has been written to output.csv.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
